---
title: "Metrics"
author: "Roy Emanuel II"
output:
    md_document:
        variant: markdown_github
---
# Stochastic Validation
  The goal of this is to build random profiles for input into the
  resilience models.

  The first steps are to set the random seed and to build the time
  column for the data frame.
```{r}

source("metrics.R")
set.seed(123)
beginTime <- 0
lastTime <- 100
res <- 1

baseTime <- data.frame(endTime = lastTime, resolution = res)

```
## Random failure times
The first example will be a randomized time to failure with a constant
    time to recover and levels of recovery. This needs to be done carefully.
    If the TTF is greater than the total time, it should be a constant
    performance.  I made changes to the metrics file to cover for this.
    For now we are assuming an exponential function.

```{r}
TTF <- ceiling(rexp(n=10, rate = 1/30))

TTFdf <- data.frame(failTime = TTF,
                    recTime = TTF + 40,
                    preLevel = 1,
                    failLevel = 0.1,
                    recLevel = 1.2
                    ) %>%
                        mutate(func = "step")


```
TTFdf is a data.frame that my resLoop function uses to define the performance
      vector. Now, let's run resLoop with some dummy variables for Need
      and resilience variables.

```{r}
r <- data.frame(tDelta = 30,
                decay = 0,
                sigma = 0)
needConstant <- data.frame(func = "constantNeed",
                cLevel = 0.8,
                startTime = NA,
                 slope = NA)

TTFresilience <- resLoop(time = baseTime,
                            need = needConstant,
                            performance = TTFdf,
                            resFactors = r)
dim(TTFresilience)

pltData <- randomResilience %>%
    filter(Time == 80) %>%
        select(QR, EQR, TQR, ETQR, Rho, extRho, statQuoResilience,
               extResilience, pRun)
pltData <- melt(pltData, id.vars = "pRun")
tPlot <- ggplot(pltData, aes(variable, value)) + geom_point()
tPlot
```

## Random recovery times and random failure times
   Now let's build a data.frame with a random recovery time. This will
   be a lognormal recovery time with a mean of 20 and vary about 5 from it
     $ \varphi(t) $ test for inline rendering of mathcode
     
```{r}
TTR <- data.frame(nums = ceiling(rlnorm(10, meanlog = log(1600/sqrt(1700)), sdlog = log(1700/1600))))
TTRF <- TTFdf %>% mutate(recTime = TTF + TTR$nums)
print(TTRF)
logPlot <- ggplot(TTR, aes(x=nums)) + geom_histogram(binwidth = 1)

TTRFresilience <- resLoop(time = baseTime,
                            need = needConstant,
                            performance = TTRF,
                            resFactors = r)
dim(TTRFresilience)

pltrData <- TTRFresilience %>%
    filter(Time == 80) %>%
        select(QR, EQR, TQR, ETQR, Rho, extRho, statQuoResilience,
               extResilience, pRun)
pltrData <- melt(pltrData, id.vars = "pRun")
rPlot <- ggplot(pltrData, aes(variable, value)) + geom_point()
rPlot
```

## Vary the failure level.
   First we use the Beta distribution skewed to zero. Then we replace
   the failure levels with this value.
```{r}
   FL <- data.frame(nums = rbeta(10, shape1 = .5, shape2 = 2))
   betaPlot <- ggplot(FL, aes(x=nums)) + geom_histogram(binwidth = .05)
   TTRFF <- TTRF %>% mutate(failLevel = FL$nums)
   print(perfLevel)

   TTRFFresilience <- resLoop(time = baseTime,
                            need = needConstant,
                            performance = perfLevel,
                          resFactors = r)
   dim(TTRFFresilience)

   pltbData <- TTRFFresilience %>%
       filter(Time == 80) %>%
           select(QR, EQR, TQR, ETQR, Rho, extRho, statQuoResilience,
                  extResilience, pRun)
   pltbData
   pltbData <- melt(pltbData, id.vars = "pRun")
   bPlot <- ggplot(pltbData, aes(variable, value)) + geom_point()
   bPlot
```   